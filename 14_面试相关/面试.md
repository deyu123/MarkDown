# 面试

#### 

```sql
-- 1. 订单id, 城市id, 配送员id, 日期
按天算每个城市配送量前十的配送员及订单量
-- 2. object 和 class 和 trait 
-- 3. 布隆过滤器
-- 4. Spark 优化
	1. FastUtil 
		a. 是什么？
		b. 场景？ ①外部变量②算子函数
	2. 序列化
  	a. java 序列化
  	b. kryo 序列化
	3. 推测执行
	4. shuffle 
		a. 32k-64k
		b.28m-96m
		c.3-10
		d. memoryFraction
		e. bypassmergeThreshold
		f. consolidatefiles
-- 5. Hbase 的预分区
1. Hbase 默认建表时，有个region, 这个region 的rowkey 是没有边界的，startkey, endKey, 在插入的时候，所有数据都是默认插入到这个region中的， 随着数据量的增加， 会进行split， 分成两个region, 
2. 产生两个问题：
  a: 数据一致往一个region 中写，会有写热点问题
  b: region split 会消耗宝贵的集群IO 资源， 
  c: 所以在建表是加上每个region 起始和终止的rowkey, 这样rowkey 就会均匀的命中每个region , 就不会出现热点问题，和split 几率大大降低
  d: split 过程：
   1）由单个region和 region server 发生，牵扯很多服务，zookeeper, master 都有涉及
   2）split 前后通知master,更新meta 表使client发现新的子region, 更新hdfs 中的目录和文件。为了错误的发生回滚，region server在内存中保留着split 执行的日志
-- 6. 怎么做数据治理的
-- 7. spark cache 和 persist 的区别
1. cache 也是底层也是调用persist 方法（persist(StorageLevet.MEMORY_ONLY)
2. 将缓存的RDD 存入到内存中，但是如果内存不过也会释放一下，如果重新计算的话，会从确实的部分开始计算，不会从所有的数据开始计算

-- 8. left seme join 与 left join 
	1.好处：遇到右表重复的记录，左表会跳过，性能会更高，而left join 是一直遍历，在右表有重复的情况下，left seme join 只会产生一条，join会产生多条，也会是		left seme join 效率更高
	2. 但是最后的结果只是出在左边的类名
	
-- 9. Spark 实现topN
  val conf = new SparkConf().setMaster("local[*]").setAppName("topN")
  val sc = new SparkContext(conf)
	val file = sc.read.textFile("\text").map(_.split("\t"))
	val res = file.groupByKey(line => line._1 -> line._2.toList.sortWith(_>_).take(3))
	res.foreach(println)
	sc.stop

-- 10. Synchronized 和 lock 的区别
1. synchronized 能实现的lock 都能实现，lock比sysnchronized 更灵活更好用
2. synchronized 是自动上锁加锁，lock 是手动上锁加锁

-- 11. Runable 和 callable 区别
1. 返回值： call 有，run 没有
2. 异常 : call 有， run 没有
3. 方法： call 方法，run 方法

-- 12. checkpoint 
1. 切断血缘关系，实现容错

-- 13. DataFream 与 DataSet 的区别：
1. DataFream 是分布式容器，类似传统的数据库二维表格，记录结构化的信息，schema 支持嵌套的数据结构，(struct , map, array)
2. Dataset 是 DataFream 的扩展， 具有类型检查， 也具有DataFream 的查询优化
	a. 支持编码解码器， 需要访问非堆数据的时，避免序列化整个对象，提高效率
	b. 用样例类定义结构信息，样例类中的属性可以直接映射
3.DataSet 是强类型的， DataFream 只知道字段，不知道类型

-- 14. Driver 与 Executor 
1. Driver : 
	a. 将用户程序转化为作业
	b. 在executor 之间调度任务task
	c. 跟踪executor 执行情况
	d. 通过ui 展示查询
2. executor 
	a. 负责运行spark 应用的任务
	b. 将结果返回给驱动器进程
	c. 通过块管理器，缓存RDD 提供内存式存储, rdd 在executor 提供缓存加速运算

-- 15. 什么是spark块管理器(BlockManager)
1. 提供内存式存储
2. blockManage 运行在每个节点上(driver 和 executor ), 提供本地或远程节点的内存，磁盘，堆外内存的中block管理
3. 存储体系狭义上就是BlockManger
4. 广义上，包括整个集群中的各个BlockManager ,BlockInfoManger,DiskBlockManger , DiskStore , MemoryBlockmanager,MemoryStore ，以及对整个BlockManager 管理的，BlockmanagerMaster 还有对外提供的block 的上传下载服务的blockTransferServer

-- 16. 什么是spark 的 schedulerbackend 的实现
1. 可用资源，executor 注册信息的状态
2. 多种实现，对接不同的资源管理系统
3. 原来是mesos的， 后来为了兼容性，提供standlone 模式，

-- 17. Spark 提交任务的几种模式
1.standalone
2.mesos
3.yarn 

client, cluster , driver 运行的位置，

-- 18. 单链表删除倒数第K位
-- 19. HashMap 底层实现原理
-- 20. Spark 推测执行原理

在spark作业运行中，一个stage里面的不同task的执行时间可能不一样，有的task很快就执行完成了，而有的可能执行很长一段时间也没有完成。造成这种情况的原因可能是集群内机器的配置性能不同、网络波动、或者是由于数据倾斜引起的。而推测执行就是当出现同一个stage里面有task长时间完成不了任务，spark就会在不同的executor上再启动一个task来跑这个任务，然后看哪个task先完成，就取该task的结果，并kill掉另一个task。其实对于集群内有不同性能的机器开启这个功能是比较有用的，但是如果仅仅是数据倾斜问题可能用处就不是很大，因为即使换了机器执行，它的本质问题–数据量大并未解决，所以也有可能会执行很长的一段时间。

-- 21. 线程的进程的区别

1. 线程是进程一个实体，是CPU 调度和分派的基本单位，线程自己不拥有系统资源，只需要一些必不可少的资源(程序计数器，一组寄存器和栈)，与同一个进程其他的线程共享全部资源
2. 同一个进程多个线程并发执行(更加类似一个执行体的概念)
3. 进程有独立的地址空间，进程崩溃，不会对别的进程产生影响，线程只是一个执行路径，有自己的堆栈局部变量，但是线程没有地址空间，多进程比多线程健壮性好，切换时耗费资源较大，效率差一下，
4. Spark 和 MR 中的线程和进程
 a: MR 中每个Task 运行在独立的JVM 进程之上的，释放占用的资源后，不能被其他的task服用，每个task 都要经历：申请资源-> 运行task -> 释放资源的过程，对于迭代式计算就是一个噩梦，
 b: Spark 中，每个Executor 配有一定数量的slot, 可以运行多个shuffleMapTask 或者ReduceTask,
 c: Execotor 是一个JVM 进程，每个Task 则是Exector 的进程
 d: 用广播变量的时候，在Executor 将广播的数据或者文件只加载一次，与Task 共享内存，而不想MapReduce 一样， 每个Task 都加载一次
 
 
-- 22. tcp 和udp 的区别
tcp 优点:可靠稳定， 慢，效率低， 握手，确认，窗口，重传，拥塞控制
udp 优点：快，无状态的协议，受攻击：UDF flood 攻击

-- 23. redis zset 的实现
1. ziplist 压缩双向链表
2. skiplist , 跳表实现

-- 24. Hive 的 行转列，列转行
行转列： lanter view explode(split(stage, ":"))
列转行：concat_ws(":", collect_set("stage"))  group by uid


-- 25. 最长公共子序列

public static int lcs(String str1, String str2) {
    int len1 = str1.length();
    int len2 = str2.length();
    int c[][] = new int[len1+1][len2+1];
    for (int i = 0; i <= len1; i++) {
        for( int j = 0; j <= len2; j++) {
            if(i == 0 || j == 0) {
                c[i][j] = 0;
            } else if (str1.charAt(i-1) == str2.charAt(j-1)) {
                c[i][j] = c[i-1][j-1] + 1;
            } else {
                c[i][j] = max(c[i - 1][j], c[i][j - 1]);
            }
        }
    }
    return c[len1][len2];
}

-- 26. 数仓的血缘关系
1.好处
	a: 数据溯源
	b: 评估数据价值：数据受众，数据更新量级，数据更新频次
	c: 反馈数据质量
	
2. Oozie 来Dag 图，来展示
3. 将依赖写入到mysql中管理，图表展示


-- 27. 数仓的设计模型
数据集市：将数据仓库中的数据整合，重构，汇总，传递给数据集市
数据集市的好处：
 	1）从数据仓库查询性能出现问题，将查询已到数据集市
 	2）安全：每个部门控制自己的数据
 	3）数据一致性：数据集市中的数据都来源于数据仓库，有效消除了数据不一致性
 	
数据仓库模型：
关系数据模型：三个范式：
第一范式：原子性
第二范式：满足第一范式没有部分依赖
第三范式：满足第二范式没有传递依赖

维度数据模型：
星型模型：一个事实表，多个一层为维度度
雪花模型：一个事实表，多个多层维度表，比较靠近第三范式
星座模型：基于多个事实表，事实表之间有维度表

-- 28. 项目中的亮点，及解决方案，使用的技术
1. 数仓主题域的建设：资产主题域，游戏主题域
2. 用户画像系统
	1）标签主题
  a. 用户基础属性：性别，年龄，城市，星座
	b. 用户生命周期：用户来源(注册的一级二级渠道，首次特征(好友桌，亲友圈，金币场，比赛场)，末次特征(最一次登录APP日期，好亲金比)，活跃时段
	c. 用户消费行为：用户资产数据，房卡，钻石，金币，红包卷，道具(首充金额，数量，消耗数量，)
	d. 用户广告行为：广告点击展示次数
                 
	
	2）标签类型
	a. 基础标签： 性别，年龄，城市，星座
	b. 统计标签：近7日，活跃天数，活跃时长，近7日活跃次数，用户注册信息，设备中获得
	c. 算法标签：近 7日 登录率
	
	
-- 29.sparkstreaming 背压模式原理
1. 越来越多的数据被接受，数据的处理速度跟上，导致数据堆积，出现executor 端OOM 的情况
2. 解决方案：
	a. spark 1.5 之后，receive 配置 spark.streaming.receiver.maxRate 参数，限制每秒接受数据的量
	b. driver 方案，spark.sparkstreaming.kafka.maxReceiverPartition 限制kafka 分区最多读取的记录个数, 根据batch 处理的条数和时间估算出一个速率

	
-- 30.spark on hive 和 hive on spark 的区别
1. Spark On Hive 
 a. 通过spark sql 使用Hive语句,来操作Hive 底层使用的还是spark rdd
 b. 加载Hive 的配置文件，获取到Hive 的元数据信息
2. Hive On Spark 
 a. hive 查询的mapreduce 的mr 替换成spark  rdd 执行引擎


```

