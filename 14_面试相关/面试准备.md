```

```



## 1、自我介绍

```


日活：60W
注册用户：1000w
每日数据量：日志行为数据：70G
业务数据：1g
峰值数据生产速度：20M/s

产品	版本	特点
Hadoop	    2.7.2	
Flume	    1.7.0	
Kafka	    0.11.0.2	
Kafka Eagle	1.3.7	
Hive	    1.2.1	【2016-08 - 2020-08】 【2016-08 - 2017-03】【2017-04 - 至今】2019-05 - 至今【2020-03 - 至今】
Sqoop	    1.4.6	
MySQl	    5.6.24	
Azkaban	    2.5.0	
Java	    1.8	
Zookeeper	3.4.10	
Hbase	1.3.1	分布式,可扩展,海量数据存储的NoSQL数据库
Phoenix	4.14.1	1.Hbase的开源SQL皮肤,方便操作
2.支持Hbase的二级索引
Canal	1.1.2	支持任意格式的数据格式
Elasticsearch	6.3.1	对海量数据进行近实时的处理
Kibana	6.3.1	为Es设计的开源分析和可视化平台
Spark	2.1.1	1.基于内存运算,比Hadoop快100倍
2.支持Java,Python和Scala的API
3.提供了统一的解决方案
4.极易方便和Hadoop环境进行融合
Redis	3.2.5	自带去重功能
```

## 1.1 版本

![image-20200817230733364](https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic GO/20200817230740.png)

（2-5分钟，项目经验、团队合作、热爱学习、学习能力强、积极乐观）



## 6、项目中遇到哪些问题

### 6.1 oom

```
Hive中OOM

Spark中OOM
1. 我们出现过一次在本地测试没有问题，但是放到集群上跑就出现OOM异常，
2. 还出现过
```

### 6.2 kafka数据不一致

```
在kafak里面可以通过幂等性  + ack=-1 + 事务的方式实现数据的一致性，但是这样性能非常低。
```

### 6.3 组件挂了

```
Flume挂了：
第一层Flume：flume内部有take和put事务，前端是使用taildirsource，不会丢失数据，不过可能会出现重复的数据，后端只是暂时不能接收数据。所以没有什么问题，直接重启，对于重复的数据，hive的dwd层采用group by进行去重。

Kafka挂了
直接重启就行，没有什么问题。
短期没事，长期日志服务器中还有30天数据
```

###    6.4 重大节日问题

```
出现OOM和数据倾斜的问题
1. 采集通过我们会临时增加服务器，并部署上flume
2. hive端出现过数据倾斜的问题。
```

###   6.5  数据倾斜的问题

```sql
'hive的数据倾斜'
针对不同的数据倾斜，我们有不同的处理方案
1. 像我们大表的和大表关键的时候，我们会考虑将大表拆解成多个job执行，先将两个大表的用户hash(id)%5，增加一个新的字段，然后通过过滤，将相同值关联在一起进行join，开启5个job，最后对结果进行unoin all
2. 对于单个key的数据倾斜，通过随机key的方式实现二次聚合
3. 对于有多个key的数据倾斜，增加reduce的个数，将多个重复的key分散
4. 对于小表join大表，将小表加载到内存中，避免shuffle。
'小文件的问题'
1. jvm重用
2. 开启combinerHiveInputFormat
3. 开启merge
'spark的数据倾斜'
1. 
```

### 6.6.1 SparkStreaming的指标

```
1. 日活
2. 月活
3. 消费券领用的预警
4. 使用双流join并借助redis缓存数据进行处理用户购买明细分析
5. 手动维护offset，借助mysql实现
6. 常规的优化：
```



### 6.6.2 Flink的指标

```
-- 1. 使用双流进行对账：intervaljoin + between
-- 2. 海量数据去重：借助redis设计布隆过滤器去重
-- 3. pv和uv
-- 4. 求TopN:采用先预聚和打上窗口信息再分组排序 + 定时器，解决了oom现象
-- 5. 使用CEP准则处理恶意登入、恶意领取优惠券
-- 6. 统计广告的点击量
-- 7. 订单支付实时监控，使用cep

使用大容量的 Kafka 把数据先放到消息队列里面作为数据源，再使用 Flink 进行消费，不过这样会影响到一点实时性。
```



### 6.7 spark和Flink的区别

```sql
1. spark是微批次，Flink是真正的流式处理
2. Flink有非常灵活的窗口，窗口的步长和时间是非常灵活，而Spark窗口只能是采集周期的倍数.
3. Flink的session模式可以实现资源共享的，但是spark一个job封装的资源只能被当前的job使用。
4. 可以乱序时间，通过waterMark + 乱序时间 + 侧输出来处理乱序时间
5. 精准一次性消费：状态后端？端到端的一致性
   source：需要外部source支持可重新读取数据位置
   flink内部：使用checkpoint保证一致性
   
   'sink'：需要保证从故障恢复时，数据不会重复写入外部系统
   sink：两种实现方式：幂等性 或 事务
   事务分为：wal 、 2pc
   wal它是at leastst once
  
   'Flink内部'：
   实现端到端一致性
   checkpoint
   checkpoint的保存方式三种
   1. memoryStateBackend：
      状态保存：TM的内存中
      checkpoint：JM的内存中
   2. FSStateBackend
      状态保存：TM的内存中
      checkpoint：FS分布系统和JM中
   3. RocksDBStateBackend
      状态保存：TM的内存中
      checkpoint：RocksDB
 
```

### 6.7.1  Flink的定时器

```
1. 用途：
```

### 6.7.2 状态保存

```
算子状态
键控状态
```

### 6.7.2.1 Flink的双流join

```
intervaljoin + between  + process
```

### 6.7.3 窗口

```sql
按时间和次数分
时间：滚动窗口、滑动窗口、会话窗口
次数：滚动窗口、滑动窗口
窗口的API：
增'量聚合算子'
reduce和aggregate：来一条数据处理一条数据
reduce：要求输入的数据和输出的数据类型保持一致
.reduce(new ReduceFunction[(String, Int)] 
aggregate：输入和输出可以不一致
aggregate(new AggregateFunction[
'也可以自定函数'：process（）
'全窗口算子'
ProcessFuntion：特点：待一个窗口数据来齐以后再处理
process(new ProcessWindowFunction
```



### 6.8 Flink的指标

```sql
1. '风控类指标'
   优惠券恶意领用
   恶意点击广告
   恶意登入
   
2. 'PV 、UV' 
   
3. '每小时的热门商品'
   
4. '实时对账'
   连接两条流，使用状态保存的方式，将二者的信息进行比较，但是涉及到数据前后来的顺序，甚至有可能不来的情况，各种进行判断。非常的麻烦。
   后来使用cep原则，非常轻松的搞定。
```

### 6.8.1 优化

```sql
1. 统计日活时，使用redis设计布隆过滤器，其实就是位图，将一条数据存储到一个bit中，进行去重，之前有通过set集合的方式，但是一到高峰期，数据量不断地增大，对内存要求高。使用布隆过滤器，存储量减少了64分之一。
2. 计算热门商品TopN，尤其是在搞活动的时候，窗口的数据是非常大，很容易出现OOM，因为Flink是流式处理系统，对窗口内的数据进行提前预聚合功能，将一个窗口的数据转换为一条并打上窗口结束时间标记，后面按照window结束时间进行分组，并设定定时器，当窗口的数据来起以后再进行排名求topn。
3. 使用CEP规则匹配的方式处理非常情况搞定复杂的、乱序需求。
   步骤1：定义规则
   步骤2：使用规则
   定义3：获取数据
匹配的规则有：
   '条件匹配'：简单匹配 + 或匹配 + 终止条件，用的不多
   '模式序列连续'：
连续是指时间，
情况①：按照数据来的时间，则是process时间
情况②：按照数据事件的发生时间，则时间语义是事件时间

1)'严格近邻':next：表示严格近邻，必须连续，必须挨着。 

Pattern
    .begin[(String, String)]("start")
        .where(_._1 == "a")
    .next("next")
        .where(_._1 == "b")
2)'宽松近邻'：followedBy表示宽松紧邻，两个数据不必紧挨着
注意细节：
数据是：
Sensor1 1
Sensor1 2
Sensor1 3
Sensor2 16
Sensor2 18
松散的满足联合条件, 当且仅当数据为a,b或者为a,c,....，b，模式均被命中，中间的c会被忽略掉。
Pattern
    .begin[(String, String)]("start")
        .where(_._1 == "a")
    .followedBy("followedBy")//括号里面只是一个名字
        .where(_._1 == "b")
3)'非确定性宽松近邻'：followByAny：类似笛卡尔积
非确定的松散满足条件, 当且仅当数据为a,c,b,b时，对于followedBy模式而言命中的为{a,b}，对于followedByAny而言会有两次命中{a,b},{a,b}
Pattern
    .begin[(String, String)]("start")
        .where(_._1 == "a")
    .followedByAny("followedByAny") //括号里面只是一个名字
        .where(_._1 == "b")
'量词（Quantifier）'
1)'固定次数'（N）：表示批次几次，
数据集：1 2 3 4 5 ，time（3）
结果：
  1 2 3
  2 3 4 
  3 4 5 
Pattern
    .begin[(String, String)]("start")
        .where(_._1 == "sensor1")
        .times(3)
2)'多次数'（N1,N2,N3）：表示1到3
Time(m,n):表示m到n的规则都要。
例time（1,3）：表示1次、2次、3次的固定次数都要。
时刻牢记：流式，数据一条一条的来。
Pattern
    .begin[(String, String)]("start")
        .where(_._1 == "sensor1")
        .times(1,3)// 表示匹配1/2/3次规则都要。
'超时'：特别适合处理超时时间的需求，不包含临界值。
Pattern
    .begin[(String, String)]("start")
        .where(_._1 == "sensor1")
        .within(Time.minutes(5)) 
    
```

### 6.8.2 CEP的应用

```scala
   // 3. 使用CEP进行超时分析
    // 3.1 定义规则
    // CEP没法处理数据异常的情况
    val pattern: Pattern[OrderEvent, OrderEvent] = Pattern
      .begin[OrderEvent]("create")
	 .where(_.eventType == "create")
      .followedBy("pay")
      .where(_.eventType == "pay")
      .within(Time.minutes(15))
    // 3.2 应用规则
    val orderPS: PatternStream[OrderEvent] = CEP.pattern(orderKS, pattern)

    // 3.3 取出数据
    // select 可以传3个参数
    //  第一个，侧输出流的标签，用来存储匹配超时的数据
    //  第二个，超时数据的处理函数，用来定义怎么处理超时的数据，之后放入侧输出流；这就说明了它保存了超时的数据
    //  第三个，匹配上规则的数据的处理函数
    val outputTag = new OutputTag[String]("timeout")
    val resultDS: DataStream[String] = orderPS.select(outputTag)(
      (timeoutDatas, ts) => {
        timeoutDatas.toString()
      }
    )(
      data => {
        data.toString()
      }
    )

```



### 6.9 检查点的实现

```
检查点的实现：
1. Flink检查点算法:异步分界线快照,Chandy-Lamport分布式快照算法。
2. JobManager协调各个TaskManager进行checkpoint存储，checkpoint保存在 StateBackend中，默认StateBackend是内存级的，也可以改为文件级的进行持久化保存。


1)第一条数据来了之后，开启一个 kafka 的事务（transaction），正常写入 kafka 分区日志但标记为未提交，这就是“预提交”
2)jobmanager 触发 checkpoint 操作，barrier 从 source 开始向下传递，遇到 barrier 的算子将状态存入状态后端，并通知 jobmanager
3)sink 连接器收到 barrier，保存当前状态，存入 checkpoint，通知 jobmanager，并开启下一阶段的事务，用于提交下个检查点的数据
4)jobmanager 收到所有任务的通知，发出确认信息，表示 checkpoint 完成
5)sink 任务收到 jobmanager 的确认信息，正式提交这段时间的数据
6)外部kafka关闭事务，提交的数据可以正常消费了。
```

### 6.10 时间语义

```
1. Flink的时间语义有：
  当前系统时间：process time
  事件时间：event time
  进入flink的时间：ingestion time
2. watermark：水位，水位线，水位标记，是一种标记，用来触发计算的标记，创建完成以后自动混入数据中。
   当 watermark >= 窗口的结束时间时，会触发窗口的计算
   在窗口中
   正序的情况下：watermark  = eventtime，窗口关闭时间 watermark  = window结束时间
   乱序时间： watermark = eventtime - 处理乱序时间，窗口关闭时间：watermark  = window结束时间
   乱序+允许迟到数据： watermark = eventtime - 处理乱序时间，窗口关闭时间：watermark  = window结束时间 + 允许迟到数据
   
   窗口的开始时间= eventtime - （eventtime - offset + windowsizi） % WindowsSize
   窗口的结束时间= 窗口开始时间  + 窗口时间 -1ms

3. watermark更新时间
   有两种，一种是周期性的更新，指定时间间隔更新一次
          一种是间接性的更新，来一条数据更新一次。
          
4. watermark是单调递增的 
```

### 6.11 ProcessFunction

```
可以获取定时器、窗口信息watermark信息
ontimer方法，是定时器被触发时的执行逻辑
可以设定定时器
上下文对象.timeService.注册事件时间或系统时间(time)
```

### 6.12 项目中遇到的什么比较困难的问题

```
1. 数据倾斜
   hive的数据倾斜
   spark的数据倾斜
2. 性能和参数调优
   flume的调优
   hive的调优
   Spark的调优
   Flink的优化
3. OOM处理
```


